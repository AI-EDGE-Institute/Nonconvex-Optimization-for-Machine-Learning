<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Schedule</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #dddddd;
            text-align: left;
            padding: 8px;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>

<h2>Nonconvex Optimization for Machine Learning</h2>

<table>
    <thead>
        <tr>
            <th scope="col">Module</th>
            <th scope="col">Topic</th>
            <th scope="col">Notes</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="text-align-justify">1. Course Info &amp; Introduction</td>
            <td class="text-align-justify">1. Course Info &amp; Introduction</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN1%20Course%20Info/LN1.pdf">Lecture 1</a></td>
        </tr>
        <tr>
            <td class="text-align-justify" colspan="1" rowspan="6">2. First-Order Methods for Nonconvex Optimization</td>
            <td class="text-align-justify">2-1. Math Background Review</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-1.pdf">Lecture 2-1</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">2-2. Convexity</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-2.pdf">Lecture 2-2</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">2-3. Gradient Descent</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-3.pdf">Lecture 2-3</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">2-4. Stochastic Gradient Descent<br />
            (General Expectation Minimization, Finite-Sum Minimization)</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-4.pdf">Lecture 2-4</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">2-5. Variance-Reduced Methods<br />
            (SAG, SVRG, SAGA, SPIDER, PAGE)</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-5.pdf">Lecture 2-5</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">2-6. Adaptive Methods<br />
            (AdaGrad, RMSProp, Adam)</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN2%20First%20Order%20Methods/LN2-6.pdf">Lecture 2-6</a></td>
        </tr>
        <tr>
            <td class="text-align-justify" colspan="1" rowspan="2">3. Federated and Decentralized Learning</td>
            <td class="text-align-justify">3-1. Federated Learning<br />
            (Distributed Learning, FedAvg)</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN3%20Federated%20and%20Decentralized%20Learning/LN3-1.pdf">Lecture 3-1</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">3-2. Decentralized Learning<br />
            (Decentralized SGD, Gradient Tracking)</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN3%20Federated%20and%20Decentralized%20Learning/LN3-2.pdf">Lecture 3-2</a></td>
        </tr>
        <tr>
            <td class="text-align-justify" colspan="1" rowspan="2">4. Zeroth-Order Methods for Nonconvex Optimization</td>
            <td class="text-align-justify">4-1. ZO Methods with Random Directions of Gradient Estimation</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN4%20Zeroth-Order%20Methods/LN4-1.pdf">Lecture 4-1</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">4-2. Variance-Reduced Zeroth-Order Methods</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN4%20Zeroth-Order%20Methods/LN4-2.pdf">Lecture 4-2</a></td>
        </tr>
        <tr>
            <td class="text-align-justify" colspan="1" rowspan="2">5. First-Order Nonconvex Optimization with Special Geometric Structure</td>
            <td class="text-align-justify">5-1. The PL Condition and NTK</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN5%20Nonconvex%20Optimization%20with%20Special%20Geometric%20Structures/LN5-1.pdf">Lecture 5-1</a></td>
        </tr>
        <tr>
            <td class="text-align-justify">5-2. NTK and Weak-Quasi-Convexity</td>
            <td class="text-align-justify"><a href="https://github.com/AI-EDGE-Institute/Nonconvex-Optimization-for-Machine-Learning/blob/main/Lecture%20Notes/LN5%20Nonconvex%20Optimization%20with%20Special%20Geometric%20Structures/LN5-2.pdf">Lecture 5-2</a></td>
        </tr>
    </tbody>
</table>

</body>
</html>
